{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "coderapir_basic_s2s.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOEQWNayQHhwnxHO11HsBiM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdf10528236/cake/blob/main/coderapir_basic_s2s.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "X8lzOV6fqRkJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import regex\n",
        "import string\n",
        "import random\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "INPUT_CHARS = \"\".join(\n",
        "    sorted(set(\"\".join(string.ascii_letters)))) + \" (),;.\\\"\"\n",
        "\n",
        "OUTPUT_CHARS = \"\".join(\n",
        "    sorted(set(\"\".join(string.ascii_letters)))) + \" (),;.\\\"\"\n"
      ],
      "metadata": {
        "id": "QMloW5ZTHjqj"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_str_to_ids(date_str, chars): \n",
        "\n",
        "    return [chars.index(c) for c in date_str]\n",
        "\n",
        "\n",
        "def prepare_date_strs(data_strs, chars=INPUT_CHARS):\n",
        "    X_ids = [data_str_to_ids(dt, chars) for dt in data_strs]\n",
        "    X = tf.ragged.constant(X_ids, ragged_rank=1)\n",
        "    return (X + 1).to_tensor()  # using 0 as the padding token ID\n",
        "\n",
        "\n",
        "def create_dataset(x, y):\n",
        "\n",
        "    return prepare_date_strs(x, INPUT_CHARS), prepare_date_strs(y, OUTPUT_CHARS)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hwuJrHLmeljA"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('printf_100thouthands.csv')\n",
        "\n",
        "\n",
        "\n",
        "X_train, Y_train = create_dataset(df['wrong'][:60000], df['correct'][:60000])\n",
        "X_valid, Y_valid = create_dataset(\n",
        "    df['wrong'][60000:80000], df['correct'][60000:80000])\n",
        "X_test, Y_test = create_dataset(\n",
        "    df['wrong'][80000:99999], df['correct'][80000:99999])\n"
      ],
      "metadata": {
        "id": "aCLIVseLewRX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AATK4xKJkFi0",
        "outputId": "8f09c4e8-b3d7-4c6b-caa5-48faf1e28a1a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(23,), dtype=int32, numpy=\n",
              "array([42, 44, 35, 40, 46, 32, 59,  3, 12, 47,  7, 43,  7, 38,  7, 59, 55,\n",
              "       57,  0,  0,  0,  0,  0], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## First version: a very basic seq2seq model"
      ],
      "metadata": {
        "id": "rwj7kFhDbs-N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "embedding_size = 32\n",
        "max_output_length = Y_train.shape[1]\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "encoder = keras.models.Sequential([\n",
        "    keras.layers.Embedding(input_dim=len(INPUT_CHARS) + 1,\n",
        "                            output_dim=embedding_size,\n",
        "                            input_shape=[None]),\n",
        "    keras.layers.LSTM(128)\n",
        "])\n",
        "\n",
        "decoder = keras.models.Sequential([\n",
        "    keras.layers.LSTM(128, return_sequences=True),\n",
        "    keras.layers.Dense(len(OUTPUT_CHARS) + 1, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model = keras.models.Sequential([\n",
        "    encoder,\n",
        "    keras.layers.RepeatVector(max_output_length),\n",
        "    decoder\n",
        "])\n",
        "\n",
        "optimizer = keras.optimizers.Nadam()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit(X_train, Y_train, epochs=20,\n",
        "                    validation_data=(X_valid, Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdUjGaHPewW3",
        "outputId": "c9515666-6d89-4c09-b553-1ababfb1cdb1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 82s 42ms/step - loss: 1.3528 - accuracy: 0.6719 - val_loss: 1.0598 - val_accuracy: 0.7415\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 1.0581 - accuracy: 0.7404 - val_loss: 1.0476 - val_accuracy: 0.7425\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 1.0343 - accuracy: 0.7443 - val_loss: 1.0134 - val_accuracy: 0.7462\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 1.0277 - accuracy: 0.7443 - val_loss: 1.0123 - val_accuracy: 0.7459\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 1.0120 - accuracy: 0.7457 - val_loss: 1.0072 - val_accuracy: 0.7459\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.9760 - accuracy: 0.7481 - val_loss: 0.9357 - val_accuracy: 0.7508\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.8694 - accuracy: 0.7572 - val_loss: 0.8010 - val_accuracy: 0.7627\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 80s 42ms/step - loss: 0.7499 - accuracy: 0.7683 - val_loss: 0.6985 - val_accuracy: 0.7704\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.6486 - accuracy: 0.7809 - val_loss: 0.6114 - val_accuracy: 0.7867\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 80s 42ms/step - loss: 0.5886 - accuracy: 0.7911 - val_loss: 0.5635 - val_accuracy: 0.7943\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.5362 - accuracy: 0.8023 - val_loss: 0.5176 - val_accuracy: 0.8064\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.4963 - accuracy: 0.8145 - val_loss: 0.4813 - val_accuracy: 0.8213\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.4684 - accuracy: 0.8259 - val_loss: 0.4553 - val_accuracy: 0.8287\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.4367 - accuracy: 0.8383 - val_loss: 0.4265 - val_accuracy: 0.8439\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.4076 - accuracy: 0.8513 - val_loss: 0.3918 - val_accuracy: 0.8544\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 80s 43ms/step - loss: 0.3692 - accuracy: 0.8660 - val_loss: 0.3554 - val_accuracy: 0.8716\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.3357 - accuracy: 0.8801 - val_loss: 0.3236 - val_accuracy: 0.8846\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.3035 - accuracy: 0.8933 - val_loss: 0.2886 - val_accuracy: 0.9000\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.2723 - accuracy: 0.9068 - val_loss: 0.2611 - val_accuracy: 0.9103\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 79s 42ms/step - loss: 0.2350 - accuracy: 0.9222 - val_loss: 0.2296 - val_accuracy: 0.9244\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def ids_to_date_strs(ids, chars=OUTPUT_CHARS):\n",
        "    return [\"\".join([(\" \" + chars)[index] for index in sequence])\n",
        "            for sequence in ids]"
      ],
      "metadata": {
        "id": "1xpORb3Xft79"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_input_length = X_train.shape[1]\n",
        "\n",
        "def prepare_date_strs_padded(date_strs):\n",
        "    X = prepare_date_strs(date_strs)\n",
        "    if X.shape[1] < max_input_length:\n",
        "        X = tf.pad(X, [[0, 0], [0, max_input_length - X.shape[1]]])\n",
        "    return X\n",
        "\n",
        "def convert_date_strs(date_strs):\n",
        "    X = prepare_date_strs_padded(date_strs)\n",
        "    pids = model.predict(X)\n",
        "    ids = np.argmax(pids, axis=2)\n",
        "    return ids_to_date_strs(ids)"
      ],
      "metadata": {
        "id": "BIRkdZ4hmUE6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['wrong'][80000],df['wrong'][80001],df['wrong'][80002],df['wrong'][80003],df['wrong'][80004],df['wrong'][80005]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0EP_cDbNnyh",
        "outputId": "a3c2088c-d232-4859-ce56-8ab0bd7e3ba1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('print(\"CvIzCutGqq\");',\n",
              " 'printf(hlQohZEEN\");',\n",
              " 'printf(\"HqBSU\"),',\n",
              " 'pritf(\"s\");',\n",
              " 'printf( (\"oFeg\");',\n",
              " 'pritf(\"CQK\");')"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "convert_date_strs([df['wrong'][80000],df['wrong'][80001],df['wrong'][80002],df['wrong'][80003],df['wrong'][80004],df['wrong'][80005]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w3DE5crsmXVg",
        "outputId": "4369e7b2-c368-4259-fcc2-84f510022d47"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['printf(\"CvAoKqtpqq\");',\n",
              " 'printf(\"hOQzPVEEO\"); ',\n",
              " 'printf(\"HqBSU\");     ',\n",
              " 'printf(\"s\");         ',\n",
              " 'printf(\"oFUg\");      ',\n",
              " 'printf(\"CQK\");       ']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second version: feeding the shifted targets to the decoder (teacher forcing)"
      ],
      "metadata": {
        "id": "iop2gwNWb1rJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sos_id = len(OUTPUT_CHARS) + 1\n",
        "\n",
        "def shifted_output_sequences(Y):\n",
        "    sos_tokens = tf.fill(dims=(len(Y), 1), value=sos_id)\n",
        "    #print(Y)\n",
        "    #print(\"sos=\",sos_tokens)\n",
        "    #print(tf.concat([sos_tokens, Y[:, :-1]], axis=1))\n",
        "    return tf.concat([sos_tokens, Y[:, :-1]], axis=1)\n",
        "X_train_decoder = shifted_output_sequences(Y_train)\n",
        "X_valid_decoder = shifted_output_sequences(Y_valid)\n",
        "X_test_decoder = shifted_output_sequences(Y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "8pwJcoJ2b8N4"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "lstm_units = 128\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "encoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "encoder_embedding = keras.layers.Embedding(\n",
        "    input_dim=len(INPUT_CHARS) + 1,\n",
        "    output_dim=encoder_embedding_size)(encoder_input)\n",
        "_, encoder_state_h, encoder_state_c = keras.layers.LSTM(\n",
        "    lstm_units, return_state=True)(encoder_embedding)\n",
        "encoder_state = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "decoder_input = keras.layers.Input(shape=[None], dtype=tf.int32)\n",
        "decoder_embedding = keras.layers.Embedding(\n",
        "    input_dim=len(OUTPUT_CHARS) + 2,\n",
        "    output_dim=decoder_embedding_size)(decoder_input)\n",
        "decoder_lstm_output = keras.layers.LSTM(lstm_units, return_sequences=True)(\n",
        "    decoder_embedding, initial_state=encoder_state)\n",
        "decoder_output = keras.layers.Dense(len(OUTPUT_CHARS) + 1,\n",
        "                                    activation=\"softmax\")(decoder_lstm_output)\n",
        "\n",
        "model = keras.models.Model(inputs=[encoder_input, decoder_input],\n",
        "                           outputs=[decoder_output])\n",
        "\n",
        "optimizer = keras.optimizers.Nadam()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=20,\n",
        "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tbarvsdxma_",
        "outputId": "720598c4-1786-4b8e-fe28-f7c3d2930ac9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1875/1875 [==============================] - 73s 37ms/step - loss: 1.1550 - accuracy: 0.7319 - val_loss: 1.0411 - val_accuracy: 0.7420\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 1.0432 - accuracy: 0.7427 - val_loss: 1.0371 - val_accuracy: 0.7423\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 1.0003 - accuracy: 0.7473 - val_loss: 0.9506 - val_accuracy: 0.7509\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.8616 - accuracy: 0.7621 - val_loss: 0.7836 - val_accuracy: 0.7705\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.6936 - accuracy: 0.7868 - val_loss: 0.6418 - val_accuracy: 0.7940\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.5993 - accuracy: 0.8067 - val_loss: 0.5492 - val_accuracy: 0.8208\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.5196 - accuracy: 0.8294 - val_loss: 0.4849 - val_accuracy: 0.8395\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.4483 - accuracy: 0.8523 - val_loss: 0.4616 - val_accuracy: 0.8492\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.3929 - accuracy: 0.8705 - val_loss: 0.3754 - val_accuracy: 0.8759\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.3469 - accuracy: 0.8852 - val_loss: 0.3412 - val_accuracy: 0.8870\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.3081 - accuracy: 0.8982 - val_loss: 0.2986 - val_accuracy: 0.9017\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.2747 - accuracy: 0.9089 - val_loss: 0.2563 - val_accuracy: 0.9146\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.2420 - accuracy: 0.9204 - val_loss: 0.2231 - val_accuracy: 0.9261\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.2083 - accuracy: 0.9325 - val_loss: 0.2758 - val_accuracy: 0.9107\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.1774 - accuracy: 0.9434 - val_loss: 0.1780 - val_accuracy: 0.9434\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.1505 - accuracy: 0.9522 - val_loss: 0.1303 - val_accuracy: 0.9588\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.1295 - accuracy: 0.9591 - val_loss: 0.1108 - val_accuracy: 0.9658\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.1125 - accuracy: 0.9645 - val_loss: 0.1099 - val_accuracy: 0.9650\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 70s 37ms/step - loss: 0.0984 - accuracy: 0.9690 - val_loss: 0.0959 - val_accuracy: 0.9695\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0863 - accuracy: 0.9730 - val_loss: 0.0945 - val_accuracy: 0.9699\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sos_id = len(OUTPUT_CHARS) + 1\n",
        "max_output_length = Y_train.shape[1]\n",
        "def predict_date_strs(date_strs):\n",
        "    X = prepare_date_strs_padded(date_strs)\n",
        "    Y_pred = tf.fill(dims=(len(X), 1), value=sos_id)\n",
        "    for index in range(max_output_length):\n",
        "        pad_size = max_output_length - Y_pred.shape[1]\n",
        "        X_decoder = tf.pad(Y_pred, [[0, 0], [0, pad_size]])\n",
        "        Y_probas_next = model.predict([X, X_decoder])[:, index:index+1]\n",
        "        Y_pred_next = tf.argmax(Y_probas_next, axis=-1, output_type=tf.int32)\n",
        "        Y_pred = tf.concat([Y_pred, Y_pred_next], axis=1)\n",
        "    return ids_to_date_strs(Y_pred[:, 1:])"
      ],
      "metadata": {
        "id": "nxustXXTytU6"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['wrong'][80000],df['wrong'][80001],df['wrong'][80002],df['wrong'][80003],df['wrong'][80004],df['wrong'][80005]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8vRjaSLzZHN",
        "outputId": "e6899159-53ff-41e7-d902-da616176d16b"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('printf(\"XpedDxYYU\";',\n",
              " 'printf(\"GlBs\";',\n",
              " 'print(\"ColNe\");',\n",
              " 'pintf(\"rQGIWCN\");',\n",
              " 'printf(\"diVPQmA\";',\n",
              " 'print(\"BgqhH\");')"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_date_strs([df['wrong'][80000],df['wrong'][80001],df['wrong'][80002],df['wrong'][80003],df['wrong'][80004],df['wrong'][80005]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3j9oqsVywgM",
        "outputId": "8ae81196-d891-4704-9cdc-e5bef23b8c4c"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['printf(\"XpedTDqYY\"); ',\n",
              " 'printf(\"GlBs\");      ',\n",
              " 'printf(\"ColNe\");     ',\n",
              " 'printf(\"rQGIWCN\");   ',\n",
              " 'printf(\"diVPQmA\");   ',\n",
              " 'printf(\"BgqhH\");     ']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Third version: using TF-Addons's seq2seq implementation"
      ],
      "metadata": {
        "id": "t5_3YjhjzdyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You may need to install tensorflow_addons\n",
        "!pip install tensorflow_addons"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFLHrAegziCl",
        "outputId": "5fe52002-7806-4e31-d920-f4979e7f51f7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 41.3 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 34.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 16.2 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 17.5 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 14.5 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 16.1 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 13.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 13.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_addons as tfa\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "units = 128\n",
        "\n",
        "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
        "\n",
        "encoder_embeddings = keras.layers.Embedding(\n",
        "    len(INPUT_CHARS) + 1, encoder_embedding_size)(encoder_inputs)\n",
        "\n",
        "decoder_embedding_layer = keras.layers.Embedding(\n",
        "    len(INPUT_CHARS) + 2, decoder_embedding_size)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "encoder = keras.layers.LSTM(units, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
        "\n",
        "decoder_cell = keras.layers.LSTMCell(units)\n",
        "output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
        "\n",
        "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell,\n",
        "                                                 sampler,\n",
        "                                                 output_layer=output_layer)\n",
        "final_outputs, final_state, final_sequence_lengths = decoder(\n",
        "    decoder_embeddings,\n",
        "    initial_state=encoder_state)\n",
        "Y_proba = keras.layers.Activation(\"softmax\")(final_outputs.rnn_output)\n",
        "\n",
        "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                           outputs=[Y_proba])\n",
        "optimizer = keras.optimizers.Nadam()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=25,\n",
        "                    validation_data=([X_valid, X_valid_decoder], Y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnkXdchIHRk1",
        "outputId": "1de25aea-6d76-477b-b7fe-20a399f3a213"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 72s 37ms/step - loss: 1.1497 - accuracy: 0.7321 - val_loss: 1.0402 - val_accuracy: 0.7422\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 1.0187 - accuracy: 0.7448 - val_loss: 0.9794 - val_accuracy: 0.7469\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.9483 - accuracy: 0.7486 - val_loss: 0.8984 - val_accuracy: 0.7512\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.8443 - accuracy: 0.7574 - val_loss: 0.7731 - val_accuracy: 0.7657\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.7200 - accuracy: 0.7740 - val_loss: 0.6742 - val_accuracy: 0.7795\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.6316 - accuracy: 0.7921 - val_loss: 0.5907 - val_accuracy: 0.8033\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.5552 - accuracy: 0.8145 - val_loss: 0.5144 - val_accuracy: 0.8293\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.4788 - accuracy: 0.8423 - val_loss: 0.4449 - val_accuracy: 0.8554\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.3981 - accuracy: 0.8715 - val_loss: 0.3635 - val_accuracy: 0.8843\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.3270 - accuracy: 0.8966 - val_loss: 0.3039 - val_accuracy: 0.9049\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 68s 36ms/step - loss: 0.2708 - accuracy: 0.9152 - val_loss: 0.2659 - val_accuracy: 0.9159\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.2244 - accuracy: 0.9305 - val_loss: 0.1979 - val_accuracy: 0.9386\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.1864 - accuracy: 0.9422 - val_loss: 0.1735 - val_accuracy: 0.9456\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.1559 - accuracy: 0.9513 - val_loss: 0.1695 - val_accuracy: 0.9468\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.1316 - accuracy: 0.9591 - val_loss: 0.1239 - val_accuracy: 0.9624\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.1114 - accuracy: 0.9653 - val_loss: 0.1135 - val_accuracy: 0.9648\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0956 - accuracy: 0.9703 - val_loss: 0.1080 - val_accuracy: 0.9653\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0813 - accuracy: 0.9749 - val_loss: 0.0804 - val_accuracy: 0.9748\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0702 - accuracy: 0.9782 - val_loss: 0.0730 - val_accuracy: 0.9772\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0611 - accuracy: 0.9812 - val_loss: 0.0638 - val_accuracy: 0.9803\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0534 - accuracy: 0.9835 - val_loss: 0.0483 - val_accuracy: 0.9854\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0470 - accuracy: 0.9855 - val_loss: 0.0440 - val_accuracy: 0.9870\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0411 - accuracy: 0.9875 - val_loss: 0.0481 - val_accuracy: 0.9847\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0364 - accuracy: 0.9889 - val_loss: 0.0313 - val_accuracy: 0.9906\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 69s 37ms/step - loss: 0.0327 - accuracy: 0.9900 - val_loss: 0.0368 - val_accuracy: 0.9887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "[df['wrong'][80000],df['wrong'][80001],df['wrong'][80002],df['wrong'][80003],df['wrong'][80004],df['wrong'][80005]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlOY_6wwOhsV",
        "outputId": "f7c79fc6-8d70-4331-f63b-e3392bd5299e"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['printf(\"XpedDxYYU\";',\n",
              " 'printf(\"GlBs\";',\n",
              " 'print(\"ColNe\");',\n",
              " 'pintf(\"rQGIWCN\");',\n",
              " 'printf(\"diVPQmA\";',\n",
              " 'print(\"BgqhH\");']"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predict_date_strs([df['wrong'][80000],df['wrong'][80001],df['wrong'][80002],df['wrong'][80003],df['wrong'][80004],df['wrong'][80005]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNknsE9BHT1u",
        "outputId": "9038d26f-76d8-4413-8141-501c33999407"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['printf(\"XpedDxYYU\"); ',\n",
              " 'printf(\"GlBs\");      ',\n",
              " 'printf(\"ColNe\");     ',\n",
              " 'printf(\"rQGIWCN\");   ',\n",
              " 'printf(\"diVPQmA\");   ',\n",
              " 'printf(\"BgqhH\");     ']"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inference_sampler = tfa.seq2seq.sampler.GreedyEmbeddingSampler(\n",
        "    embedding_fn=decoder_embedding_layer)\n",
        "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
        "    decoder_cell, inference_sampler, output_layer=output_layer,\n",
        "    maximum_iterations=max_output_length)\n",
        "batch_size = tf.shape(encoder_inputs)[:1]\n",
        "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
        "final_outputs, final_state, final_sequence_lengths = inference_decoder(\n",
        "    start_tokens,\n",
        "    initial_state=encoder_state,\n",
        "    start_tokens=start_tokens,\n",
        "    end_token=0)\n",
        "\n",
        "inference_model = keras.models.Model(inputs=[encoder_inputs],outputs=[final_outputs.sample_id])"
      ],
      "metadata": {
        "id": "jzFpec8THVeT"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fast_predict_date_strs(date_strs):\n",
        "    X = prepare_date_strs_padded(date_strs)\n",
        "    Y_pred = inference_model.predict(X)\n",
        "    return ids_to_date_strs(Y_pred)"
      ],
      "metadata": {
        "id": "jNNQC9GwHYVG"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[df['wrong'][80000],df['wrong'][80001],df['wrong'][80002],df['wrong'][80003],df['wrong'][80004],df['wrong'][80005]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQJyjMn_O2hQ",
        "outputId": "674d142b-a7f7-477b-fef8-dd367f5f3f49"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['printf(\"XpedDxYYU\";',\n",
              " 'printf(\"GlBs\";',\n",
              " 'print(\"ColNe\");',\n",
              " 'pintf(\"rQGIWCN\");',\n",
              " 'printf(\"diVPQmA\";',\n",
              " 'print(\"BgqhH\");']"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fast_predict_date_strs([df['wrong'][80000],df['wrong'][80001],df['wrong'][80002],df['wrong'][80003],df['wrong'][80004],df['wrong'][80005]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5US1iTaHZ_j",
        "outputId": "0dfd3486-60ce-4702-99b7-6d1da2f13b0a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['printf(\"XpedDxYYU\"); ',\n",
              " 'printf(\"GlBs\");      ',\n",
              " 'printf(\"ColNe\");     ',\n",
              " 'printf(\"rQGIWCN\");   ',\n",
              " 'printf(\"diVPQmA\");   ',\n",
              " 'printf(\"BgqhH\");     ']"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fourth version: using TF-Addons's seq2seq implementation with a scheduled sampler\n"
      ],
      "metadata": {
        "id": "EF6zmvP7cGvC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_addons as tfa\n",
        "\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "n_epochs = 20\n",
        "encoder_embedding_size = 32\n",
        "decoder_embedding_size = 32\n",
        "units = 128\n",
        "\n",
        "encoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "decoder_inputs = keras.layers.Input(shape=[None], dtype=np.int32)\n",
        "sequence_lengths = keras.layers.Input(shape=[], dtype=np.int32)\n",
        "\n",
        "encoder_embeddings = keras.layers.Embedding(\n",
        "    len(INPUT_CHARS) + 1, encoder_embedding_size)(encoder_inputs)\n",
        "\n",
        "decoder_embedding_layer = keras.layers.Embedding(\n",
        "    len(INPUT_CHARS) + 2, decoder_embedding_size)\n",
        "decoder_embeddings = decoder_embedding_layer(decoder_inputs)\n",
        "\n",
        "encoder = keras.layers.LSTM(units, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_embeddings)\n",
        "encoder_state = [state_h, state_c]\n",
        "\n",
        "sampler = tfa.seq2seq.sampler.ScheduledEmbeddingTrainingSampler(\n",
        "    sampling_probability=0.,\n",
        "    embedding_fn=decoder_embedding_layer)\n",
        "# we must set the sampling_probability after creating the sampler\n",
        "# (see https://github.com/tensorflow/addons/pull/1714)\n",
        "sampler.sampling_probability = tf.Variable(0.)\n",
        "\n",
        "decoder_cell = keras.layers.LSTMCell(units)\n",
        "output_layer = keras.layers.Dense(len(OUTPUT_CHARS) + 1)\n",
        "\n",
        "decoder = tfa.seq2seq.basic_decoder.BasicDecoder(decoder_cell,\n",
        "                                                 sampler,\n",
        "                                                 output_layer=output_layer)\n",
        "final_outputs, final_state, final_sequence_lengths = decoder(\n",
        "    decoder_embeddings,\n",
        "    initial_state=encoder_state)\n",
        "Y_proba = keras.layers.Activation(\"softmax\")(final_outputs.rnn_output)\n",
        "\n",
        "model = keras.models.Model(inputs=[encoder_inputs, decoder_inputs],\n",
        "                           outputs=[Y_proba])\n",
        "optimizer = keras.optimizers.Nadam()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "def update_sampling_probability(epoch, logs):\n",
        "    proba = min(1.0, epoch / (n_epochs - 10))\n",
        "    sampler.sampling_probability.assign(proba)\n",
        "\n",
        "sampling_probability_cb = keras.callbacks.LambdaCallback(\n",
        "    on_epoch_begin=update_sampling_probability)\n",
        "history = model.fit([X_train, X_train_decoder], Y_train, epochs=n_epochs,\n",
        "                    validation_data=([X_valid, X_valid_decoder], Y_valid),\n",
        "                    callbacks=[sampling_probability_cb])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHvnVm6NcJ8O",
        "outputId": "8e6ec3e3-dd6b-4d72-d0e6-71ec65f99005"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_8/basic_decoder_4/decoder/while/gradients/model_8/basic_decoder_4/decoder/while/cond_1_grad/Identity_4:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_8/basic_decoder_4/decoder/while/gradients/model_8/basic_decoder_4/decoder/while/cond_1_grad/Identity_3:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_8/basic_decoder_4/decoder/while/gradients/model_8/basic_decoder_4/decoder/while/cond_1_grad/Identity_5:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/indexed_slices.py:450: UserWarning: Converting sparse IndexedSlices(IndexedSlices(indices=Tensor(\"gradient_tape/model_8/basic_decoder_4/decoder/while/gradients/model_8/basic_decoder_4/decoder/while/cond_grad/gradients/grad_ys_0_indices:0\", shape=(None,), dtype=int32), values=Tensor(\"gradient_tape/model_8/basic_decoder_4/decoder/while/gradients/model_8/basic_decoder_4/decoder/while/cond_grad/gradients/grad_ys_0_values:0\", shape=(None, 32), dtype=float32), dense_shape=Tensor(\"gradient_tape/model_8/basic_decoder_4/decoder/while/gradients/model_8/basic_decoder_4/decoder/while/cond_grad/gradients/grad_ys_0_shape:0\", shape=(2,), dtype=int32))) to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"shape. This may consume a large amount of memory.\" % value)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 81s 41ms/step - loss: 1.1485 - accuracy: 0.7322 - val_loss: 1.0395 - val_accuracy: 0.7424\n",
            "Epoch 2/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 1.0319 - accuracy: 0.7439 - val_loss: 1.0036 - val_accuracy: 0.7454\n",
            "Epoch 3/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 1.0001 - accuracy: 0.7460 - val_loss: 0.9934 - val_accuracy: 0.7458\n",
            "Epoch 4/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.9593 - accuracy: 0.7485 - val_loss: 0.8990 - val_accuracy: 0.7521\n",
            "Epoch 5/20\n",
            "1875/1875 [==============================] - 76s 41ms/step - loss: 0.8318 - accuracy: 0.7601 - val_loss: 0.7605 - val_accuracy: 0.7694\n",
            "Epoch 6/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.7193 - accuracy: 0.7779 - val_loss: 0.6709 - val_accuracy: 0.7899\n",
            "Epoch 7/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.6404 - accuracy: 0.7974 - val_loss: 0.6198 - val_accuracy: 0.8015\n",
            "Epoch 8/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.5679 - accuracy: 0.8182 - val_loss: 0.5325 - val_accuracy: 0.8297\n",
            "Epoch 9/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.4968 - accuracy: 0.8405 - val_loss: 0.4721 - val_accuracy: 0.8457\n",
            "Epoch 10/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.4409 - accuracy: 0.8579 - val_loss: 0.4237 - val_accuracy: 0.8603\n",
            "Epoch 11/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.3960 - accuracy: 0.8706 - val_loss: 0.3777 - val_accuracy: 0.8761\n",
            "Epoch 12/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.3587 - accuracy: 0.8813 - val_loss: 0.3474 - val_accuracy: 0.8846\n",
            "Epoch 13/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.3247 - accuracy: 0.8927 - val_loss: 0.3197 - val_accuracy: 0.8949\n",
            "Epoch 14/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.2850 - accuracy: 0.9072 - val_loss: 0.2738 - val_accuracy: 0.9100\n",
            "Epoch 15/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.2562 - accuracy: 0.9170 - val_loss: 0.2448 - val_accuracy: 0.9211\n",
            "Epoch 16/20\n",
            "1875/1875 [==============================] - 77s 41ms/step - loss: 0.2293 - accuracy: 0.9260 - val_loss: 0.2231 - val_accuracy: 0.9270\n",
            "Epoch 17/20\n",
            "1875/1875 [==============================] - 78s 41ms/step - loss: 0.2078 - accuracy: 0.9325 - val_loss: 0.2042 - val_accuracy: 0.9335\n",
            "Epoch 18/20\n",
            "1875/1875 [==============================] - 78s 41ms/step - loss: 0.1860 - accuracy: 0.9400 - val_loss: 0.1776 - val_accuracy: 0.9421\n",
            "Epoch 19/20\n",
            "1875/1875 [==============================] - 78s 42ms/step - loss: 0.1671 - accuracy: 0.9460 - val_loss: 0.1675 - val_accuracy: 0.9447\n",
            "Epoch 20/20\n",
            "1875/1875 [==============================] - 78s 42ms/step - loss: 0.1521 - accuracy: 0.9504 - val_loss: 0.1501 - val_accuracy: 0.9507\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax_temperature = tf.Variable(1.)\n",
        "\n",
        "inference_sampler = tfa.seq2seq.sampler.SampleEmbeddingSampler(\n",
        "    embedding_fn=decoder_embedding_layer,\n",
        "    softmax_temperature=softmax_temperature)\n",
        "inference_decoder = tfa.seq2seq.basic_decoder.BasicDecoder(\n",
        "    decoder_cell, inference_sampler, output_layer=output_layer,\n",
        "    maximum_iterations=max_output_length)\n",
        "batch_size = tf.shape(encoder_inputs)[:1]\n",
        "start_tokens = tf.fill(dims=batch_size, value=sos_id)\n",
        "final_outputs, final_state, final_sequence_lengths = inference_decoder(\n",
        "    start_tokens,\n",
        "    initial_state=encoder_state,\n",
        "    start_tokens=start_tokens,\n",
        "    end_token=0)\n",
        "\n",
        "inference_model = keras.models.Model(inputs=[encoder_inputs],\n",
        "                                     outputs=[final_outputs.sample_id])"
      ],
      "metadata": {
        "id": "gOOYSCUGcSIY"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def creative_predict_date_strs(date_strs, temperature=1.0):\n",
        "    softmax_temperature.assign(temperature)\n",
        "    X = prepare_date_strs_padded(date_strs)\n",
        "    Y_pred = inference_model.predict(X)\n",
        "    return ids_to_date_strs(Y_pred)"
      ],
      "metadata": {
        "id": "3w3Sc8YbcTnY"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[df['wrong'][80000],df['wrong'][80001],df['wrong'][80002],df['wrong'][80003],df['wrong'][80004],df['wrong'][80005]]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rk270TJIjFlB",
        "outputId": "c4bd95e4-7d10-4feb-bf22-e7b17fa779c3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['printf(\"XpedDxYYU\";',\n",
              " 'printf(\"GlBs\";',\n",
              " 'print(\"ColNe\");',\n",
              " 'pintf(\"rQGIWCN\");',\n",
              " 'printf(\"diVPQmA\";',\n",
              " 'print(\"BgqhH\");']"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(42)\n",
        "\n",
        "creative_predict_date_strs([df['wrong'][80000],df['wrong'][80001],df['wrong'][80002],df['wrong'][80003],df['wrong'][80004],df['wrong'][80005]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-z6kPIhi-HO",
        "outputId": "c6e4ddc2-9ece-4ba3-8982-7d4109936286"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['printf(\"XpewKEUqv\"); ',\n",
              " 'printf(\"GlBs\");      ',\n",
              " 'printf(\"ColNe\");     ',\n",
              " 'printf(\"rQGIWwN\");   ',\n",
              " 'printf(\"diaPlmA\");   ',\n",
              " 'printf(\"BgshH\");     ']"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    }
  ]
}